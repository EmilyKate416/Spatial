{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#note reasoning for batches is in comparing_outliers.csv\n",
    "#0 manual processing in interactive R session on cluster \n",
    "#1 to process each sample individually via slurm submission - avoiding as it results in different numbers of rows in count matrix of each sample which prevents merging later\n",
    "#2 to process in bulk up to or including nnsvg step\n",
    "\n",
    "skip ahead to 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. To manually run the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# #open interactive node session, in terminal connect to cluster then enter\n",
    "\n",
    "srun --pty --job-name=interactive_r --mem=32G --cpus-per-task=4 --partition=epyc --time=024:00:00 bash \n",
    "#activate r environment with\n",
    "micromambda activate r_env\n",
    "#open R\n",
    "R\n",
    "Sys.setenv(PATH = paste(Sys.getenv(\"PATH\"), \"/home/lythgo02/micromamba/envs/r_env\", sep = \":\"))\n",
    "#then run the commands in 20240204_QC_final_workflow.rmd but you will need to adapt the code for the samples you want to process as logbatch mitochondrial filters and the arbitrary mitochondrial filters batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to run by as individual samples, open ssh terminal and set of individual slurm jobs for each (using a different script for the log batch and the arbitrary batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#1.0\n",
    "\n",
    "cd /mnt/scratchc/fmlab/lythgo02/visium_data/\n",
    "for SAMPLE in SITSA3 SITSB2 SITSB4 SITSC1 SITSC3 SITSD3 SITSE4 SITSF2 SITSF4 ; \n",
    "do sbatch \n",
    "--job-name=${SAMPLE} \n",
    "--output=logs/${SAMPLE}.out \n",
    "--error=logs/${SAMPLE}.err \n",
    "--time=100:00:00 \n",
    "--mem=32G \n",
    "--cpus-per-task=8 \n",
    "--partition=epyc \n",
    "--wrap=\"Rscript single_sample_process_logmito.r ${SAMPLE}\"; \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#1.2\n",
    "\n",
    "cd /mnt/scratchc/fmlab/lythgo02/visium_data/\n",
    "\n",
    "for SAMPLE in SITSA1 SITSA2 SITSA4 SITSB1 SITSB3 SITSC2 SITSC4 SITSD1 SITSD2 SITSD4 SITSE2 SITSG2 SITSH2 ; \n",
    " do sbatch \n",
    " --job-name=${SAMPLE} \n",
    " --output=logs/${SAMPLE}.out \n",
    " --error=logs/${SAMPLE}.err \n",
    " --time=048:00:00 \n",
    " --mem=32G \n",
    " --cpus-per-task=8 \n",
    " --partition=epyc \n",
    " --wrap=\"Rscript single_sample_processing_arbitrary.r ${SAMPLE}\"; \n",
    " done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once they have finished running cd into the respectiv folders and run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#1.3\n",
    "\n",
    "cd logbatch \n",
    "\n",
    "for SAMPLE in post_gettophgvSITSA3 post_gettophgvSITSB2 post_gettophgvSITSB4 post_gettophgvSITSC1 post_gettophgvSITSC3 post_gettophgvSITSD3 post_gettophgvSITSE4 post_gettophgvSITSF2 post_gettophgvSITSF4; \n",
    " do     sbatch --job-name=${SAMPLE}            \n",
    " --output=logs/${SAMPLE}.out            \n",
    " --error=logs/${SAMPLE}.err            \n",
    " --time=0100:00:00            \n",
    " --mem=32G            \n",
    " --cpus-per-task=8            \n",
    " --partition=epyc            \n",
    " --wrap=\"Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/logbatch/nnsvg_logbatch.r ${SAMPLE}\"; \n",
    " done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#1.4\n",
    "\n",
    "cd into arbitrary\n",
    "\n",
    "for SAMPLE in post_gettophgvSITSA1 post_gettophgvSITSA2 post_gettophgvSITSA4 post_gettophgvSITSB1 post_gettophgvSITSB3 post_gettophgvSITSC2 post_gettophgvSITSC4 post_gettophgvSITSD1 post_gettophgvSITSD2 post_gettophgvSITSD4 post_gettophgvSITSE2 post_gettophgvSITSG2 post_gettophgvSITSH2;  \n",
    "do     \n",
    "sbatch \n",
    "--job-name=${SAMPLE}            \n",
    "--output=logs/${SAMPLE}.out            \n",
    "--error=logs/${SAMPLE}.err            \n",
    "--time=0100:00:00            \n",
    "--mem=32G            \n",
    "--cpus-per-task=8            \n",
    "--partition=epyc            \n",
    "--wrap=\"Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/arbitrary/nnsvg_arbitrary.r ${SAMPLE}\";\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1.5 then pick up after running nnsvg \n",
    "#open interactive r session within micromamba r_rnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.5\n",
    "\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "library(spatialLIBD)\n",
    "library(nnSVG)\n",
    "library(SpatialExperiment)  \n",
    "library(scater)\n",
    "library(AnnotationHub)\n",
    "library(tidyverse)\n",
    "library(ggspavis)\n",
    "library(scran)\n",
    "library(DT)\n",
    "projDir = \"/mnt/scratchc/fmlab/lythgo02/visium_data/\"\n",
    "\n",
    "\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/logbatch/nnsvg\"\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"^nnsvg\", full.names = TRUE)\n",
    "\n",
    "# Print out the list of files\n",
    "print(files)\n",
    "\n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "logbatch <- c(\"SITSA3\", \"SITSB2\", \"SITSB4\", \n",
    "                 \"SITSC1\",\"SITSC3\",\"SITSD3\",\n",
    "                 \"SITSE4\",\"SITSF2\", \"SITSF4\")\n",
    "\n",
    "names(files) <- logbatch\n",
    "# Initialize a list to store each sample\n",
    "spe_list <- list()\n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    "  # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "    # Add unique barcodes\n",
    "  spe$barcode <- rownames(colData(spe))\n",
    "  spe$barcodeid <- gsub(\"-1$\", paste0(\"-\", sample_name), spe$barcode)\n",
    "  rownames(colData(spe)) <- spe$barcodeid\n",
    "  spe$sample_id <- sample_name\n",
    "\n",
    "  colData(spe)$qc_mito <- colData(spe)$log_is_outlier_mad\n",
    "  colData(spe) <- colData(spe)[ , !(colnames(colData(spe)) %in% c(\"log_mito_percent\",\"log_median_mito_percent\",\"log_mad_mito_percent\",\"log_deviation_above_median\",\"log_is_outlier_mad\"))]\n",
    "\n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#1.6 load arbitrary batch \n",
    "\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/arbitrary/nnsvg\"\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"^nnsvg\", full.names = TRUE)\n",
    "\n",
    "# Print out the list of files\n",
    "print(files)\n",
    " \n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "arbitrary <- c(\"SITSA1\",\"SITSA2\",\"SITSA4\", \"SITSB1\", \"SITSB3\", \n",
    "                 \"SITSC2\",\"SITSC4\",\"SITSD1\",\"SITSD2\", \"SITSD4\",\n",
    "                 \"SITSE2\",\"SITSG2\", \"SITSH2\")\n",
    "\n",
    "names(files) <- arbitrary \n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    " # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "    # Add unique barcodes\n",
    "  spe$barcode <- rownames(colData(spe))\n",
    "  spe$barcodeid <- gsub(\"-1$\", paste0(\"-\", sample_name), spe$barcode)\n",
    "  rownames(colData(spe)) <- spe$barcodeid\n",
    "  spe$sample_id <- sample_name\n",
    "  \n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#1.6 bind all into one spatial object \n",
    "\n",
    "\n",
    "spe <- do.call(cbind, spe_list) #wont work because different row numbers # wont work if row numbers differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To process all samples together in a slurm submission (either up to nnsvg or inc nnsvg)\n",
    "#make sure you are updating and using the scratch scripts, there are also copies on mnt but outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#2.0\n",
    "\n",
    "sbatch /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/nnsvg.sh\n",
    "\n",
    "#which is \n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --error=nnSVG.err\n",
    "#SBATCH --time=0200:00:00             \n",
    "#SBATCH --cpus-per-task=32      \n",
    "#SBATCH --mem=120G                   \n",
    "#SBATCH --partition=epyc     \n",
    "\n",
    "\n",
    "# Run the R script\n",
    "#Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/sample_specific_filtering_wholeworkflow.r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#there is also a script called end_stage_hvg_nnsvg_singlesamplejob.r which is the end section of the workflow to submit single jobs for each sample for hvg and nnsvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 then process each sample separately for hvg and nnsvg via slurm job using following script \n",
    "\n",
    "# note after separating out individual samples, SITSA1 and SITSD3 have rows with 0 count (causing nnsvg to fail) for:\n",
    "#SITSA1 - HNRNPCL3, TMOD4, REG1A USP17L10, PVRIG CNTNAP3B, ZP1, C13orf46 ZP2, PAGE2, TGIF2LY, PCDH11Y \n",
    "#SITSD3 - HNRNPCL3, PRAMEF33, UBE2U, CA14 AL590560.2, WDR64, SPDYA, NMS, ZDHHC19, USP17L10, HTN3, PCBD2, HIST1H4E, PVRIG \n",
    "         #ASZ1, AKR1C4, OOSP1, ZP1, DEFB131B, C13orf46, GOLGA6L6, TEPP, ALOX15, ANKRD30B, ZNF541, BPIFB2, BPIFB6, BPIFB3 \n",
    "         #USP41, CRYBB2, GAGE1, PAGE2, SLC25A5, TGIF2LY, PRKY \n",
    "# remove zero expression genes\n",
    "ix_zero_genes <- rowSums(counts(spe_SITSD3)) == 0\n",
    "table(ix_zero_genes)\n",
    "\n",
    "# identify genes with 0 expression\n",
    "true <- ix_zero_genes[ix_zero_genes]\n",
    "\n",
    "if (sum(ix_zero_genes) > 0) {\n",
    "  spe_SITSD3 <- spe_SITSD3[!ix_zero_genes, ]}\n",
    "\n",
    "# remove spots with zero expression\n",
    "ix_zero_spots <- colSums(counts(spe_SITSA1)) == 0\n",
    "table(ix_zero_spots) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#2.1 \n",
    "for sample in SITSA1 SITSA2 SITSA3 SITSA4 SITSB1 SITSB2 SITSB3 SITSB4 SITSC1 SITSC2 SITSC3 SITSC4 SITSD1 SITSD2 SITSD3 SITSD4 SITSE2 SITSE4 SITSF2 SITSF4 SITSG2 SITSH2; \n",
    "do     sbatch ../scripts/nnsvg.sh $sample; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 then open interactive R session and proceed as follows\n",
    "We will take the top ranking HVGs and top ranking SVGs, reduce the dimensions with PCA on each, and then integrate and cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "srun --pty --job-name=interactive_r --mem=68G --cpus-per-task=4 --partition=epyc --time=100:00:00 bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.4 fitting top HVGs\n",
    "\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "library(spatialLIBD)\n",
    "library(nnSVG)\n",
    "library(SpatialExperiment)  \n",
    "library(scater)\n",
    "library(AnnotationHub)\n",
    "library(tidyverse)\n",
    "library(ggspavis)\n",
    "library(scran)\n",
    "library(DT)\n",
    "projDir = \"/mnt/scratchc/fmlab/lythgo02/visium_data/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#load samples\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/\" \n",
    "\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"spe_sub_modelgenevar\", full.names = TRUE) #to load hvgs results\n",
    "#hvg results stored in rowData(spe_ibject)$hvg\n",
    "\n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "\n",
    "names(files) <- samplesheet\n",
    "\n",
    "# Initialize a list to store each sample\n",
    "spe_list <- list()\n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    " # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "\n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction on top HVGs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#playing with pca and umap on hvg \n",
    "\n",
    "# Compute PCA for HVGs (highly variable genes)\n",
    "set.seed(123)\n",
    "\n",
    "#already run getTopHVGs and stored in hvg column of rowData(spe_object)$hvg\n",
    "#pull out list of hvgs\n",
    "#initialise list to store hvgs\n",
    "hvg <- vector(\"list\", length(spe_list))\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "     #extract hvg list\n",
    "     hvg[[i]] <- as.data.frame(rowData(spe_list[[i]])) %>%\n",
    "     filter(hvg==TRUE) %>%\n",
    "     pull(symbol)\n",
    "\n",
    " spe_list[[i]] <- runPCA(spe_list[[i]], subset_row = hvg[[i]])  \n",
    "}\n",
    "## Set seed\n",
    "set.seed(987)\n",
    "## Compute UMAP on top 50 PCs\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "\n",
    "spe_list[[i]] <- runUMAP(spe_list[[i]], dimred = \"PCA\") \n",
    "}\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "\n",
    "## Check correctness - names\n",
    "print(reducedDimNames(spe_list[[i]])) \n",
    "#check correctness\n",
    "print(dim(reducedDim(spe_list[[i]], \"UMAP\")))\n",
    "\n",
    "## Update column names for easier plotting\n",
    "colnames(reducedDim(spe_list[[i]], \"UMAP\")) <- paste0(\"UMAP\", 1:2)\n",
    "}\n",
    "\n",
    "plots <- vector(\"list\", length(spe_filt))\n",
    "#plots\n",
    "for (i in seq_along(spe_list)) {\n",
    "     #extract sample id\n",
    "     sample_id <- spe_list[[i]]$sample_id[i]\n",
    "     \n",
    "plots[[i]] <- ggplot(data = as.data.frame(spe_list[[i]]@int_colData@listData$reducedDims$PCA),\n",
    "       aes(x = PC1, y = PC2, colour = spe_list[[i]]@colData$ground_truth)) + \n",
    "  geom_point(size = 0.5) + \n",
    "  scale_colour_brewer(type = \"qual\") + \n",
    "  labs(title = paste(\"Reduced dimensions: PCA (Sample:\", sample_id, \")\"),\n",
    "       x = \"PC1\",\n",
    "       y = \"PC2\",\n",
    "       colour = \"Layers\") +\n",
    "  theme_classic()\n",
    "}\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "save_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/\"\n",
    "\n",
    "for (i in seq_along(plots)) {\n",
    "  # Define the file name based on the sample_id for uniqueness, with the full path\n",
    "  file_name <- paste0(save_dir, \"plot_\", spe_list[[i]]$sample_id[1], \".png\")\n",
    "  \n",
    "  # Save the plot using ggsave\n",
    "  ggsave(filename = file_name, plot = plots[[i]], width = 8, height = 6)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Get top SVGs\n",
    "\n",
    "nnsvg\n",
    "The results are stored in the rowData of the SpatialExperiment object.\n",
    "The main results of interest are:\n",
    "LR_stat: likelihood ratio (LR) statistics used to rank SVGs\n",
    "rank: rank of top SVGs according to LR statistics\n",
    "pval: approximate p-values\n",
    "padj: approximate p-values adjusted for multiple testing\n",
    "prop_sv: effect size defined as proportion of spatial variance\n",
    "\n",
    "The following section compares the most spatially variable genes for each sample to get the top consistently SVGs across all samples\n",
    "Stored in df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#check if gene names are the same\n",
    "# Initialize a list to store gene names for each sample\n",
    "gene_names_list <- lapply(spe_list, function(spe) rownames(rowData(spe)))\n",
    "\n",
    "# Compare each sample to the first one (assumed to be the reference)\n",
    "reference_genes <- gene_names_list[[1]]\n",
    "sample_names <- names(gene_names_list)\n",
    "\n",
    "# Check if all gene names are in the same order\n",
    "same_order <- sapply(gene_names_list, function(genes) identical(genes, reference_genes))\n",
    "\n",
    "# Display results\n",
    "if (all(same_order)) {\n",
    "  cat(\"✅ All samples have gene names in the same order.\\n\")\n",
    "} else {\n",
    "  cat(\"❌ Some samples have gene names in a different order:\\n\")\n",
    "  print(sample_names[!same_order])\n",
    "}\n",
    "\n",
    "#combining svgs\n",
    "#rank svg results if gene names and order match in each object \n",
    "\n",
    "sample_ids <- names(spe_list)\n",
    "\n",
    "# Get the number of genes (rows) from one of the spe objects, \n",
    "# assuming all spe objects have the same genes\n",
    "num_genes <- nrow(rowData(spe_list[[1]]))\n",
    "\n",
    "#matrix of svg ranks across samples \n",
    "# Initialize the res_ranks matrix with NA values\n",
    "res_ranks <- matrix(NA, nrow = num_genes, ncol = length(spe_list))\n",
    "rownames(res_ranks) <- rownames(rowData(spe_list[[1]]))  # Gene IDs from the row data of any spe object\n",
    "colnames(res_ranks) <- names(spe_list)  # Sample names from the spe_list\n",
    "# Loop through each sample in spe_list\n",
    "for (s in seq_along(spe_list)) {\n",
    "  sample_name <- names(spe_list)[s]  # Get the current sample name\n",
    "  \n",
    "  # Get the rank data from the current spe object\n",
    "  gene_data <- as.data.frame(rowData(spe_list[[sample_name]]))\n",
    "  \n",
    "  # Check if the \"rank\" column exists\n",
    "  if (\"rank\" %in% colnames(gene_data)) {\n",
    "    # Extract ranks for the current sample\n",
    "    ranks <- gene_data[, \"rank\", drop = FALSE]  # Retain ranks column as a data frame\n",
    "    rownames(ranks) <- rownames(gene_data)  # Ensure gene names match\n",
    "    \n",
    "    # Assign the ranks to the appropriate column in res_ranks matrix\n",
    "    res_ranks[rownames(ranks), sample_name] <- ranks$rank\n",
    "  } else {\n",
    "    stop(\"No 'rank' column found in the data for sample: \", sample_name)\n",
    "  }\n",
    "}\n",
    "\n",
    "# remove genes that weren't ranked in any samples\n",
    "ix_allna <- apply(res_ranks, 1, function(r) all(is.na(r)))\n",
    "res_ranks <- res_ranks[!ix_allna, ]\n",
    "\n",
    "dim(res_ranks)\n",
    "\n",
    "# calculate average ranks\n",
    "# note missing values due to filtering for samples\n",
    "avg_ranks <- rowMeans(res_ranks, na.rm = TRUE)\n",
    "\n",
    "\n",
    "# calculate number of samples where each gene is within top 100 ranked SVGs\n",
    "# for that sample\n",
    "n_withinTop100 <- apply(res_ranks, 1, function(r) sum(r <= 100, na.rm = TRUE))\n",
    "\n",
    "df_summary <- data.frame(\n",
    "  gene_id = rowData(spe_list[[1]])[names(avg_ranks), \"ID\"],  # Use \"ID\" for gene_id\n",
    "  gene_name = rowData(spe_list[[1]])[names(avg_ranks), \"symbol\"],  # Use \"symbol\" for gene_name\n",
    "  overall_rank = rank(avg_ranks),\n",
    "  average_rank = unname(avg_ranks),\n",
    "  n_withinTop100 = unname(n_withinTop100),\n",
    "  row.names = names(avg_ranks)\n",
    ")\n",
    "\n",
    "\n",
    "# sort by average rank\n",
    "df_summary <- df_summary[order(df_summary$average_rank), ]\n",
    "head(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of significant SVGs\n",
    "# #many are mitochondrial - should i filter out mitochrondial genes first or is it ok to filter out after ??\n",
    "table(rowData(spe_filt)$padj <= 0.05)\n",
    "## \n",
    "\n",
    "#show results for top 10 SVGs\n",
    "\n",
    "test <- rowData(spe_filt)[order(rowData(spe_filt)$rank)[1:500], ] %>% \n",
    "  as.data.frame() #%>% \n",
    "  #filter(!str_detect(symbol,\"MT-\"))\n",
    "\n",
    "# plot spatial expression of top-ranked SVG\n",
    "ix <- which(rowData(spe_filt)$rank == 1)\n",
    "ix_name <- rowData(spe_filt)$symbol[ix]\n",
    "ix_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spatial expression of a gene \n",
    "\n",
    "df <- as.data.frame(cbind(spatialCoords(spe_filt), expr = counts(spe_filt)[ix, ]))\n",
    "\n",
    "df <- as.data.frame(cbind(\n",
    "  spatialCoords(spe_filt), \n",
    "  expr = as.vector(as.matrix(counts(spe_filt))[ix, ])\n",
    "))\n",
    "ggplot(df, aes(x = pxl_col_in_fullres, y = pxl_row_in_fullres, \n",
    "               color = expr)) + \n",
    "  geom_point(size = 0.8) + \n",
    "  coord_fixed() + \n",
    "  scale_y_reverse() + \n",
    "  scale_color_gradient(low = \"gray90\", high = \"blue\", \n",
    "                       trans = \"sqrt\", breaks = range(df$expr), \n",
    "                       name = \"counts\") + \n",
    "  ggtitle(ix_name) + \n",
    "  theme_bw() + \n",
    "  theme(plot.title = element_text(face = \"italic\"), \n",
    "        panel.grid = element_blank(), \n",
    "        axis.title = element_blank(), \n",
    "        axis.text = element_blank(), \n",
    "        axis.ticks = element_blank())\n",
    "\n",
    "#ggsave(\"20250227_nnsvg_sitsa2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to extract top SVGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract top SVGs\n",
    "#can simplify and just extract top n based on rank column \n",
    "\n",
    "getTopSVGs <- function(spe, top_n = 1000) {\n",
    "  # Extract the row data from the spe object as a dataframe\n",
    "  results <- as.data.frame(rowData(spe))\n",
    "  \n",
    "  # Sort by ascending rank\n",
    "  results <- results[order(results$rank), ]\n",
    "\n",
    "  # Select the top N SVGs (top 1000 by default)\n",
    "  top_genes <- rownames(results)[seq_len(top_n)]\n",
    "\n",
    "  # Create a logical vector for top SVGs\n",
    "  svg_flag <- rownames(results) %in% top_genes\n",
    "\n",
    "  # Add the 'svg' flag to rowData of the spe object\n",
    "  rowData(spe)$svg <- svg_flag\n",
    "  \n",
    "  # Return the updated SpatialExperiment object\n",
    "  return(spe)\n",
    "}\n",
    "\n",
    "# Now, apply the function to each SpatialExperiment object in spe_list\n",
    "top_svg_list <- list()\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "  spe <- spe_list[[i]]  # Extract the current SpatialExperiment object\n",
    "  \n",
    "  # Get top 1000 SVGs for this sample\n",
    "  spe_updated <- getTopSVGs(spe, top_n = 1000)\n",
    "  \n",
    "  # Store the updated SpatialExperiment object in the list\n",
    "  top_svg_list[[i]] <- spe_updated\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_svgs <- getTopSVGs(spe_filt) #need to determine number to take ...same number as hvgs?\n",
    "\n",
    "#extract symbols and convert to character list, also shorten to the same length as hvgs\n",
    "top_svgs <- as.character(top_svgs[1:999, \"symbol\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate SVGs and HVGs\n",
    "A simple way to combine these features is to concatenate columns of principal components (PCs) calculated on the set of HVGs and the set of SVGs (excluding overlapping HVGs), and then using the combined set of features for further downstream analyses (Li et al. 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "Use PCA to reduce the dimensions of our dataset to assist clustering and UMAP to further reduce the principal components (PCs) in a two-dimensional space and produce better visualisations for the PCA.\n",
    "runPCA() function runs PCA on a SCE object, and returns an updated version of the single cell object with the PCA result added to the reducedDim slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA for HVGs (highly variable genes)\n",
    "set.seed(123)\n",
    "spe_filt <- runPCA(spe_filt, subset_row = top_hvgs)  # Restrict PCA to use only HVGs\n",
    "# Store the PCA result for HVGs in the \"PCA_HVGs\" slot\n",
    "#After running runPCA(), the result is automatically stored in a default reduced dimension slot named \"PCA\". Assign to PCA_HVGs so it wont be overwritten by svg pca\n",
    "reducedDim(spe_filt, \"PCA_HVGs\") <- reducedDim(spe_filt, \"PCA\")\n",
    "# Optional: Check the results\n",
    "reducedDimNames(spe_filt)\n",
    "\n",
    "# Remove the PCA results for HVGs (if you want to overwrite or free up memory)\n",
    "#reducedDim(spe_filt, \"PCA\") <- NULL\n",
    "\n",
    "\n",
    "# Compute PCA for SVGs (spatially variable genes)\n",
    "set.seed(123)\n",
    "spe_filt <- runPCA(spe_filt, subset_row = top_svgs)  # Restrict PCA to use only SVGs\n",
    "\n",
    "reducedDim(spe_filt, \"PCA_SVGs\") <- reducedDim(spe_filt, \"PCA\")\n",
    "# Optional: Check the results\n",
    "reducedDimNames(spe_filt)\n",
    "\n",
    "#CHECK HVGS AND SVGS IN PCA SLOTS ARE DIFFERENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# View the dimensions of the reduced dimensions for both PCA analyses\n",
    "dim(reducedDim(spe_filt, \"PCA_HVGs\"))\n",
    "dim(reducedDim(spe_filt, \"PCA_SVGs\"))\n",
    "\n",
    "# View the variance explained for both PCA analyses\n",
    "percent.var.hvgs <- attr(reducedDim(spe_filt, \"PCA_HVGs\"), \"percentVar\")\n",
    "percent.var.svgs <- attr(reducedDim(spe_filt, \"PCA_SVGs\"), \"percentVar\")\n",
    "\n",
    "# Plot variance explained for HVGs\n",
    "# Specify the file path and name for the plot (e.g., \"plot.png\")\n",
    "png(\"variance_explained_hvgs_pca_sitsa2.png\", width = 800, height = 600)\n",
    "\n",
    "plot(percent.var.hvgs, log = \"y\", xlab = \"PC\", ylab = \"Variance explained (%)\")\n",
    "abline(v = PCAtools::findElbowPoint(percent.var.hvgs), col = \"dodgerblue\")\n",
    "\n",
    "# Close the PNG device to save the plot\n",
    "dev.off()\n",
    "\n",
    "# Specify the file path and name for the plot (e.g., \"plot.png\")\n",
    "png(\"variance_explained_svgs_pca_sitsa2.png\", width = 800, height = 600)\n",
    "\n",
    "# Plot variance explained for SVGs\n",
    "plot(percent.var.svgs, log = \"y\", xlab = \"PC\", ylab = \"Variance explained (%)\")\n",
    "abline(v = PCAtools::findElbowPoint(percent.var.svgs), col = \"dodgerblue\")\n",
    "\n",
    "# Close the PNG device to save the plot\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLY GOT AS FAR AS RUNNING TO HERE, CONTINUE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate HVGs and SVGs for clustering \n",
    "# Extract the PCs for both HVGs and SVGs\n",
    "pca_hvgs <- reducedDim(spe_filt, \"PCA_HVGs\")\n",
    "pca_svgs <- reducedDim(spe_filt, \"PCA_SVGs\")\n",
    "\n",
    "# Concatenate the principal components (PCs)\n",
    "combined_pcs <- cbind(pca_hvgs, pca_svgs)\n",
    "\n",
    "# Store the concatenated PCs in the 'spe_filt' object\n",
    "reducedDim(spe_filt, \"PCA_combined\") <- combined_pcs\n",
    "\n",
    "# Check the result\n",
    "dim(reducedDim(spe_filt, \"PCA_combined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run UMAP on the set of top 50 PCs and retain top 2 UMAP components for visualization \n",
    "# compute UMAP on top 50 PCs\n",
    "set.seed(123)\n",
    "spe_filt <- runUMAP(spe_filt, dimred = \"PCA\")\n",
    "\n",
    "reducedDimNames(spe_filt)\n",
    "dim(reducedDim(spe_filt, \"UMAP\"))\n",
    "\n",
    "# update column names for easier plotting\n",
    "colnames(reducedDim(spe_filt, \"UMAP\")) <- paste0(\"UMAP\", 1:2)\n",
    "\n",
    "# plot top 2 PCA dimensions\n",
    "plotDimRed(spe_filt, type = \"PCA\")\n",
    "\n",
    "# plot top 2 UMAP dimensions\n",
    "plotDimRed(spe_filt, type = \"UMAP\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
