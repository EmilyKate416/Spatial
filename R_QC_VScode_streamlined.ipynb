{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#note reasoning for batches is in comparing_outliers.csv\n",
    "#0 manual processing in interactive R session on cluster \n",
    "#1 to process each sample individually via slurm submission - avoiding as it results in different numbers of rows in count matrix of each sample which prevents merging later\n",
    "#2 to process in bulk up to or including nnsvg step\n",
    "\n",
    "skip ahead to 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To process all samples together in a slurm submission (either up to nnsvg or inc nnsvg)\n",
    "#make sure you are updating and using the scratch scripts, there are also copies on mnt but outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#2.0\n",
    "\n",
    "sbatch /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/nnsvg.sh\n",
    "\n",
    "#which is \n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --error=nnSVG.err\n",
    "#SBATCH --time=0200:00:00             \n",
    "#SBATCH --cpus-per-task=32      \n",
    "#SBATCH --mem=120G                   \n",
    "#SBATCH --partition=epyc     \n",
    "\n",
    "\n",
    "# Run the R script\n",
    "#Rscript /mnt/scratchc/fmlab/lythgo02/visium_data/scripts/sample_specific_filtering_wholeworkflow.r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#there is also a script called end_stage_hvg_nnsvg_singlesamplejob.r which is the end section of the workflow to submit single jobs for each sample for hvg and nnsvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 then process each sample separately for hvg and nnsvg via slurm job using following script \n",
    "\n",
    "# note after separating out individual samples, SITSA1 and SITSD3 have rows with 0 count (causing nnsvg to fail) for:\n",
    "#SITSA1 - HNRNPCL3, TMOD4, REG1A USP17L10, PVRIG CNTNAP3B, ZP1, C13orf46 ZP2, PAGE2, TGIF2LY, PCDH11Y \n",
    "#SITSD3 - HNRNPCL3, PRAMEF33, UBE2U, CA14 AL590560.2, WDR64, SPDYA, NMS, ZDHHC19, USP17L10, HTN3, PCBD2, HIST1H4E, PVRIG \n",
    "         #ASZ1, AKR1C4, OOSP1, ZP1, DEFB131B, C13orf46, GOLGA6L6, TEPP, ALOX15, ANKRD30B, ZNF541, BPIFB2, BPIFB6, BPIFB3 \n",
    "         #USP41, CRYBB2, GAGE1, PAGE2, SLC25A5, TGIF2LY, PRKY \n",
    "# remove zero expression genes\n",
    "ix_zero_genes <- rowSums(counts(spe_SITSD3)) == 0\n",
    "table(ix_zero_genes)\n",
    "\n",
    "# identify genes with 0 expression\n",
    "true <- ix_zero_genes[ix_zero_genes]\n",
    "\n",
    "if (sum(ix_zero_genes) > 0) {\n",
    "  spe_SITSD3 <- spe_SITSD3[!ix_zero_genes, ]}\n",
    "\n",
    "# remove spots with zero expression\n",
    "ix_zero_spots <- colSums(counts(spe_SITSA1)) == 0\n",
    "table(ix_zero_spots) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#2.1 \n",
    "for sample in SITSA1 SITSA2 SITSA3 SITSA4 SITSB1 SITSB2 SITSB3 SITSB4 SITSC1 SITSC2 SITSC3 SITSC4 SITSD1 SITSD2 SITSD3 SITSD4 SITSE2 SITSE4 SITSF2 SITSF4 SITSG2 SITSH2; \n",
    "do     sbatch ../scripts/nnsvg.sh $sample; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 then open interactive R session and proceed as follows\n",
    "We will take the top ranking HVGs and top ranking SVGs, reduce the dimensions with PCA on each, and then integrate and cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "srun --pty --job-name=interactive_r --mem=68G --cpus-per-task=4 --partition=epyc --time=100:00:00 bash\n",
    "\n",
    "micromamba activate r_env \n",
    "\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#2.4 fitting top HVGs\n",
    "\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "library(spatialLIBD)\n",
    "library(nnSVG)\n",
    "library(SpatialExperiment)  \n",
    "library(scater)\n",
    "library(AnnotationHub)\n",
    "library(tidyverse)\n",
    "library(ggspavis)\n",
    "library(scran)\n",
    "library(DT)\n",
    "projDir = \"/mnt/scratchc/fmlab/lythgo02/visium_data/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#load samples\n",
    "load_all_data <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/\" \n",
    "\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"spe_sub_modelgenevar\", full.names = TRUE) #to load hvgs only\n",
    "\n",
    "#assign names so they are loaded into the spe with the correct identifiers\n",
    "samplesheet <- c(\"SITSA1\", \"SITSA2\", \"SITSA3\", \"SITSA4\",\n",
    "                 \"SITSB1\", \"SITSB2\", \"SITSB3\", \"SITSB4\", \n",
    "                 \"SITSC1\", \"SITSC2\", \"SITSC3\", \"SITSC4\", \n",
    "                 \"SITSD1\", \"SITSD2\", \"SITSD3\", \"SITSD4\",\n",
    "                 \"SITSE2\", \"SITSE4\", \"SITSF2\", \"SITSF4\",\n",
    "                 \"SITSG2\", \"SITSH2\")  \n",
    "\n",
    "names(files) <- samplesheet\n",
    "\n",
    "# Initialize a list to store each sample\n",
    "spe_list <- list()\n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    " # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "\n",
    "  # Store the processed sample in the list\n",
    "  spe_list[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction on top HVGs \n",
    "Top HVGs have been determined using getTopHVGs() from scran which returns top 10% (prop=0.1) of genes with highest biological variance after discarding those with bio <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute PCA for HVGs (highly variable genes)\n",
    "#I have already run \n",
    " # top_hvgs <- getTopHVGs(dec, prop = 0.1, var.field = \"bio\")\n",
    " #var.field = \"bio\"\tRanks genes by biological variability\n",
    " #prop = 0.1\tTakes top 10% of genes based on that ranking\n",
    "\n",
    " # and assigned TRUE or FALSE for hvgs\n",
    "set.seed(123)\n",
    "\n",
    "#initialise list to store hvgs\n",
    "hvg <- vector(\"list\", length(spe_list))\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "     #extract hvg list\n",
    "     hvg[[i]] <- as.data.frame(rowData(spe_list[[i]])) %>%\n",
    "     filter(hvg==TRUE) %>%\n",
    "     pull(symbol)\n",
    "\n",
    " spe_list[[i]] <- runPCA(spe_list[[i]], subset_row = hvg[[i]])  \n",
    "}\n",
    "## Set seed\n",
    "set.seed(987)\n",
    "## Compute UMAP on top 50 PCs\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "\n",
    "spe_list[[i]] <- runUMAP(spe_list[[i]], dimred = \"PCA\") \n",
    "}\n",
    "\n",
    "for (i in seq_along(spe_list)) {\n",
    "\n",
    "## Check correctness - names\n",
    "print(reducedDimNames(spe_list[[i]])) \n",
    "#check correctness\n",
    "print(dim(reducedDim(spe_list[[i]], \"UMAP\")))\n",
    "\n",
    "## Update column names for easier plotting\n",
    "colnames(reducedDim(spe_list[[i]], \"UMAP\")) <- paste0(\"UMAP\", 1:2)\n",
    "}\n",
    "\n",
    "plots <- vector(\"list\", length(spe_list))\n",
    "#plots\n",
    "for (i in seq_along(spe_list)) {\n",
    "     #extract sample id\n",
    "     sample_id <- spe_list[[i]]$sample_id[i]\n",
    "     \n",
    "plots[[i]] <- ggplot(data = as.data.frame(spe_list[[i]]@int_colData@listData$reducedDims$PCA),\n",
    "       aes(x = PC1, y = PC2, colour = spe_list[[i]]@colData$ground_truth)) + \n",
    "  geom_point(size = 0.5) + \n",
    "  scale_colour_brewer(type = \"qual\") + \n",
    "  labs(title = paste(\"Reduced dimensions: PCA (Sample:\", sample_id, \")\"),\n",
    "       x = \"PC1\",\n",
    "       y = \"PC2\",\n",
    "       colour = \"Layers\") +\n",
    "  theme_classic()\n",
    "}\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "save_dir <- \"/mnt/scratchc/fmlab/lythgo02/visium_data/single_sample_from_filtering/\"\n",
    "\n",
    "for (i in seq_along(plots)) {\n",
    "  # Define the file name based on the sample_id for uniqueness, with the full path\n",
    "  file_name <- paste0(save_dir, \"plots/plot_hvg_pca\", spe_list[[i]]$sample_id[1], \".png\")\n",
    "  \n",
    "  # Save the plot using ggsave\n",
    "  ggsave(filename = file_name, plot = plots[[i]], width = 8, height = 6)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Get top SVGs\n",
    "\n",
    "nnsvg\n",
    "The results are stored in the rowData of the SpatialExperiment object.\n",
    "The main results of interest are:\n",
    "LR_stat: likelihood ratio (LR) statistics used to rank SVGs\n",
    "rank: rank of top SVGs according to LR statistics\n",
    "pval: approximate p-values\n",
    "padj: approximate p-values adjusted for multiple testing\n",
    "prop_sv: effect size defined as proportion of spatial variance\n",
    "\n",
    "First load each spe object after having run nnsvg on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List files in the directory\n",
    "files <- list.files(path = load_all_data, pattern = \"spe_sub_nnSVG\", full.names = TRUE) #to load hvgs only\n",
    "\n",
    "\n",
    "names(files) <- samplesheet\n",
    "\n",
    "# Initialize a list to store each sample\n",
    "spe_list_nnsvg <- list()\n",
    "\n",
    "# Loop through each file and process it\n",
    "for (sample_name in names(files)) {\n",
    " # Read the Visium data\n",
    "  spe <- readRDS(files[sample_name])\n",
    "\n",
    "  # Store the processed sample in the list\n",
    "  spe_list_nnsvg[[sample_name]] <- spe \n",
    "  \n",
    "  \n",
    "  assign(paste0(\"spe_\", sample_name), spe)\n",
    "  #print progress check\n",
    "  cat(\"Loaded:\", sample_name, \"\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get top SVGs for each sample using user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each spe object in the list\n",
    "for (i in seq_along(spe_list_nnsvg)) {\n",
    "\n",
    "  spe <- spe_list_nnsvg[[i]]\n",
    "  \n",
    "  #Assign TRUE or FALSE based on ranking of gene \n",
    "  rowData(spe)$svg <- rowData(spe)$rank <=1000\n",
    "  #save it back to original list\n",
    "  spe_list_nnsvg[[i]] <- spe\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA and UMAP on top SVGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(456)\n",
    "\n",
    "#initialise list to store hvgs\n",
    "svg <- vector(\"list\", length(spe_list_nnsvg))\n",
    "\n",
    "for (i in seq_along(spe_list_nnsvg)) {\n",
    "    spe <- spe_list_nnsvg[[i]]\n",
    "    # get the rownames (gene IDs) where svg == TRUE\n",
    "    svg[[i]] <- rownames(spe)[rowData(spe)$svg == TRUE]\n",
    "    # run PCA on those genes\n",
    "    spe <- runPCA(spe, subset_row = svg[[i]])\n",
    "    # run UMAP on PCA result\n",
    "    spe <- runUMAP(spe, dimred = \"PCA\")\n",
    "    # save updated object\n",
    "    spe_list_nnsvg[[i]] <- spe\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate SVGs and HVGs\n",
    "A recent benchmark paper (Li et al. 2022) showed that integrating HVGs and SVGs to generate a combined set of features can improve downstream clustering performance in STx data. This confirms that SVGs contain additional biologically relevant information that is not captured by HVGs in these datasets. For example, a simple way to combine these features is to concatenate columns of principal components (PCs) calculated on the set of HVGs and the set of SVGs (excluding overlapping HVGs), and then using the combined set of features for further downstream analyses (Li et al. 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatnate and then perform the next stages of the workbook tutorial (clustering on  integrated VGs)\n",
    "first want to deconvolute to cell type to colour umaps by cell identity, compare with mIF and look for spatial patterns of VGs once i have done clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "Use PCA to reduce the dimensions of our dataset to assist clustering and UMAP to further reduce the principal components (PCs) in a two-dimensional space and produce better visualisations for the PCA.\n",
    "runPCA() function runs PCA on a SCE object, and returns an updated version of the single cell object with the PCA result added to the reducedDim slot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
